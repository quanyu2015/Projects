{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dataset\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)\n",
    "\n",
    "Class distribution: 357 benign \"B\", 212 malignant \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "f = urllib.urlretrieve (\"http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", \"data/wdbc.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break them into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data size is 569\n"
     ]
    }
   ],
   "source": [
    "data_file = \"data/wdbc.data\"\n",
    "raw = sc.textFile(data_file)\n",
    "\n",
    "print \"All data size is {}\".format(raw.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [17.99,10.38,122.8,1001.0,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019.0,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]),\n",
       " LabeledPoint(1.0, [20.57,17.77,132.9,1326.0,0.08474,0.07864,0.0869,0.07017,0.1812,0.05667,0.5435,0.7339,3.398,74.08,0.005225,0.01308,0.0186,0.0134,0.01389,0.003532,24.99,23.41,158.8,1956.0,0.1238,0.1866,0.2416,0.186,0.275,0.08902])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "def parse(line):\n",
    "    line_split = line.split(\",\")\n",
    "    line_final = line_split[2:33]\n",
    "    if line_split[1]=='B':\n",
    "        diagnosis = 0.0\n",
    "    if line_split[1]=='M':\n",
    "        diagnosis = 1.0\n",
    "    return LabeledPoint(diagnosis, array([float(x) for x in line_final]))\n",
    "\n",
    "parsedData = raw.map(parse)\n",
    "parsedData.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size is 411\n",
      "Test data size is 158\n"
     ]
    }
   ],
   "source": [
    "(train, test) = parsedData.randomSplit([0.7, 0.3], seed = 123)\n",
    "\n",
    "print \"Train data size is {}\".format(train.count())\n",
    "print \"Test data size is {}\".format(test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.983\n",
      "Testing accuracy = 0.93\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "\n",
    "model = LogisticRegressionWithLBFGS.train(train)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "preds1 = train.map(lambda p: (p.label, model.predict(p.features)))\n",
    "train_acc = preds1.filter(lambda (v, p): v == p).count() / float(train.count())\n",
    "print(\"Training accuracy = \" + str(round(train_acc, 3)))\n",
    "\n",
    "# Evaluating the model on testing data\n",
    "preds2 = test.map(lambda p: (p.label, model.predict(p.features)))\n",
    "test_acc = preds2.filter(lambda (v, p): v == p).count() / float(test.count())\n",
    "print(\"Testing accuracy = \" + str(round(test_acc, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.981\n",
      "Testing accuracy = 0.88\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "\n",
    "model = DecisionTree.trainClassifier(train, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxDepth=3, maxBins=10)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "preds1 = model.predict(train.map(lambda x: x.features))\n",
    "labels1 = train.map(lambda p: p.label).zip(preds1)\n",
    "train_acc = labels1.filter(lambda (v, p): v == p).count() / float(train.count())\n",
    "print(\"Training accuracy = \" + str(round(train_acc, 3)))\n",
    "\n",
    "# Evaluating the model on testing data\n",
    "preds2 = model.predict(test.map(lambda x: x.features))\n",
    "labels2 = test.map(lambda p: p.label).zip(preds2)\n",
    "test_acc = labels2.filter(lambda (v, p): v == p).count() / float(test.count())\n",
    "print(\"Testing accuracy = \" + str(round(test_acc, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeModel classifier of depth 3 with 15 nodes\n",
      "  If (feature 22 <= 106.4)\n",
      "   If (feature 27 <= 0.1546)\n",
      "    If (feature 25 <= 0.4665)\n",
      "     Predict: 0.0\n",
      "    Else (feature 25 > 0.4665)\n",
      "     Predict: 0.0\n",
      "   Else (feature 27 > 0.1546)\n",
      "    If (feature 24 <= 0.1428)\n",
      "     Predict: 0.0\n",
      "    Else (feature 24 > 0.1428)\n",
      "     Predict: 1.0\n",
      "  Else (feature 22 > 106.4)\n",
      "   If (feature 1 <= 16.83)\n",
      "    If (feature 7 <= 0.08543)\n",
      "     Predict: 0.0\n",
      "    Else (feature 7 > 0.08543)\n",
      "     Predict: 1.0\n",
      "   Else (feature 1 > 16.83)\n",
      "    If (feature 26 <= 0.1804)\n",
      "     Predict: 0.0\n",
      "    Else (feature 26 > 0.1804)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Learned classification tree model:')\n",
    "print(model.toDebugString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
